Day01

分布式ELK平台

ELK简介
 是一整套解决方案,是三个软件产品的首字母缩写
 ELK分别代表
   Elasticsearch:负责日志检索和存储(nosql数据库角色)
   Logstash:负责日志的收集和分析处理(类似php的功能)
   Kibana:负责日志的可视化(web服务器角色)
 这三款软件都是开源的,通常配合使用

ELK能做什么
 分布式日志数据集中式查询和管理
 系统监控,包含系统硬件和应用各个组件的监控(不同于zabbix,单个用户大访问也可以监控到)
 故障排查
 安全信息和事件管理
 报表功能
 
Elasticsearch
 特点
  -实时分析
  -分布式实时文件存储，将每一个字段编入索引
  -文档导向，所有的对象全部是文档
  -高可用性，易扩展，支持集群、分片和复制
  -接口友好，支持JSON
 缺点
  -没有典型意义的事务
  -是一种面向文档的数据库
  -没有提供授权和认证特性
 相关概念
  -Node:装有一个ES服务器的节点
  -Cluster:有多个Node组成的集群
  -Document:一个可被搜索的基础信息单元
  -Index：拥有相似特征的文档的集合
  -Type：一个索引中可以定义一种或多种类型
  -Filed：是ES的最小单位，相当于数据的某一列
  -Shards：索引的分片，每一个分片就是一个Shard
  -Replicas：索引的拷贝
 SQL与NoSQL
 -DB -> Databases -> Tables -> Rows -> Columns
  -关系型    数据库          表          行          列
 -ES -> Indices -> Types -> Documents -> Fields
 -ES      索引         类型         文档         域(字段)

组件elasticsearch集群
1.配置虚拟机(ip:192.168.1.11-15,name:es1-5,/etc/hosts配置五台主机)
2.安装软件包java-1.8.0-openjdk elasticsearch
3.修改配置文件/etc/elasticsearch/elasticsearch.yml
 17：cluster.name: 集群名字
 23：node.name: 本机主机名
 54：network.host: 0.0.0.0(允许访问的网段)
 68：discovery.zen.ping.unicast.hosts: ["各主机名","","",...](可以只写2，3个，但启动服务时，必须先启动此处声明的主机，否则其他节点会找不到集群)
4.启动验证 systemctl start elasticsearch
  http://IP:9200   //验证单台elasticsearch是否正常
  http://IP/_cluster/health?pretty  //验证集群是否正常
 
HTTP协议
http请求由三部分组成：请求行、消息报头、请求正文
http请求方法
 常用方法：GET，POST，HEAD
 其他方法：OPTIONS，PUT，DELETE，TRACE，CONNECT
ES常用
 PUT：增
 DELETE：删
 POST：改
 GET：查
系统命令curl常用参数
 -A  修改请求agent
 -X  设置请求方法
 -i  显示返回头信息
 curl -XPUT 118.144.89.24/info.php
 
ES插件使用
常用插件
 head插件
   -它展现ES集群的拓扑结构，并且可以通过它来进行索引(index)和节点(node)级别的操作
   -它提供一组针对集群的查询API，并将结果以json和表格式形式返回
   -它提供一些快捷菜单，用以展现集群的各种状态
 kopf插件
   -是一个ElasticSearch的管理工具
   -它提供了对ES集群操作的API
 bigdesk插件
   -是elasticsearch的一个集群监控工具
   -可以通过它来查看es集群的各种状态，如：cup、内存使用情况，索引数据、搜索情况，http连接数等
ES插件的安装、查看
 /usr/share/elasticsearch/bin/plugin list   //查看安装的插件
 /usr/share/elasticsearch/bin/plugin install file:///文件目录  //安装插件
 /usr/share/elasticsearch/bin/plugin remove  //删除插件
 http://IP:9200/_plugin/插件名    //打开插件
 
RESTful API调用
 -检查集群、节点、索引的健康度、状态和统计
 -管理集群、节点、索引的数据及元数据
 -对索引进行CRUD操作及查询操作
 -执行其他高级操作如分页、排序、过滤等
POST或PUT数据使用json格式

JSON简介
 JSON是什么
   JSON是JavaScript对象表示法,它是一种基于文本独立于语言的轻量级数据交换格式
   JSON中的分隔符限于单引号、小括号、中括号、大括号、冒号、逗号
 JSON特性
   JSON是纯文本
   JSON具有自我描述性(人类可以读懂)
   JSON具有层及结构(值中存在值,嵌套)
   JSON可通过JavaScript进行解析
 JSON语法规则
   数据在名称/值对中
   数据由逗号分隔
   大括号保存对象
   中括号保存数组
   小括号表示分组
 JSON数据的书写格式："key":"values"
 JSON复合复杂类型：
   { "诗人":
     [ {"李白":"诗仙","年代":"唐"},
      {"李白":"诗仙","年代":"唐"},
      {"李白":"诗仙","年代":"唐"},
      {"李白":"诗仙","年代":"唐"}
     ]
   }

RESTful API简单使用
 _cat API查询集群状态，节点信息
 curl http://IP:9200/_cat/?h  //帮助信息，查看详细参数
 curl http://IP:9200/_cat/xxx?v  //显示详细信息
 常用的xxx参数：health(集群健康状态)、master(主库信息)、nodes(集群主机信息)、shards(索引和数据保存信息)、indices(索引信息)
 
命令创建一个索引，json格式
curl -XPUT http://IP:9200/索引名称  -d '     //-d表示向服务器发送数据
{
  "settings":{
    "index":{
      "number_of_shards":5,
      "number_of_replicas":1
    }
  }
}'
 
增加
curl -XPUT http://192.168.1.11:9200/索引名/类型名/id -d '{
"姓名": "何南海",
"年龄": "不详",
"性别": "不详"
}'
修改
curl -XPOST http://192.168.1.11：9200/索引名/类型名/id/_update -d '{
"doc":{
 "性别": "男"
}
}'
删除
curl -XDELETE http://192.168.1.11：9200/索引名/类型名/id
curl -XDELETE http://192.168.1.11：9200/*   //删除数据库所有信息
查询
curl -XGET http://192.168.1.11：9200/索引名/类型名/id   //加?pretty竖排显示
 
kibana
 数据可视化平台工具
特点：
 -灵活的分析和可视化平台
 -实时总结流量和数据的图表
 -为不同的用户显示直观的界面
 -即使分享和嵌入的仪表板
安装kibanna
 装包kibana
 修改配置文件/opt/kibana/config/kibana.yml
  2 server.port: 5601    //若把端口改为80，可以成功启动kibana，但ss时没有端口，没有监听80端口，服务里面写死了，不能用80端口，只能是5601这个端口
  5 server.host: "0.0.0.0"        //服务器监听地址
  15 elasticsearch.url: http://192.168.1.11:9200   //声明地址，从哪里查，集群里面随便选一个
  23 kibana.index: ".kibana"    //kibana自己创建的索引
  26 kibana.defaultAppId: "discover"    //打开kibana页面时，默认打开的页面 discover
  53 elasticsearch.pingTimeout: 1500    //ping检测超时时间
  57 elasticsearch.requestTimeout: 30000    //请求超时
  64 elasticsearch.startupTimeout: 5000    //启动超时
  
导入数据使用_bulk,POST
 -批量导入数据使用POST方式,数据格式为json,url编码使用data-binary
 -文件中没有index配置的,需要在ur里面定制index和type
 curl -XPOST http://192.168.1.11:9200/_bulk --data-binary @json文件
 
查询导入的数据使用_mget,GET
 curl -XGET http://192.168.1.15:9200/_mget?pretty -d '{
 "docs":[
   {"_index": "索引名",
    "_type" : "类型名",
     "_id" : "id值"
    },
    ...
 ]
 }'


curl -XGET http://192.168.1.15:9200/_mget?pretty -d '{
 "docs":[
   {"_index" : "shakespeare",
     "_type" : "line",
       "_id" : "1"
    },
   {"_index" : "accounts",
     "_type" : "type",
       "_id" : "1"
    },
   {"_index": "logstash-2015.05.20",
    "_type" : "log",
     "_id" : "AWhZfKgVi0F9tdPUkl51"
    }
    ]}'
在图形界面http://192.168.1.20:5601/制作图表
###########################################################################

Day02

Logstash
是什么:一个数据采集、加工处理以及传输的工具
特点：
  -所有类型的数据集中处理
  -不同模式和格式数据的正常化
  -自定义日志格式的迅速扩展
  -为自定义数据源轻松添加插件
Logstash安装
  -依赖Java环境，需要安装java-1.8.0-openjdk
  -没有默认的配置文件，需要手动设置
  -安装在/opt/logstash
  
百度搜索金步国作品集(此人爱好翻译官方手册)
httpd.apache.org  //官方寻找手册
日志格式logformat  
Http默认日志文件		/var/log/httpd/access_log
访问用户IP - 访问用户名 访问具体时间 访问协议 访问结果返回值 发送文件大小 客户使用系统 使用浏览器 
 
logstash工作结构
 input   负责收集日志，读
 filter  负责处理日志，加工
 output  负责输出日志，写

书写logstash配置文件
vim /etc/logstash/logstash.conf
input{
  beats {
    port => 5044
  }
  file {
    path => [ "/tmp/a.log","...",... ]    //定义读取文件位置
    sincedb_path => "/var/lib/logstash/since.db"  //指定文件记录上次读取位置
    start_position => "beginning"    //定义第一次读取从文件头开始读取
    type => "apache.log"    //自定义类型，方便区分
  }
  tcp {
    mode => "server"     //默认为服务端,若为客户端以下为去寻找的主机和端口
    host => "0.0.0.0"    //监听的主机地址
    port => 8888  	//监听的端口
    type => "tcp.log"    //类型，自定义
  }
  udp {
    port => 8888
    type => "udp.log"
  }
  syslog {
    type => "sys.log"
  }
}
filter{
  if [type] == "weblog" {  //匹配filebeat配置文件中的document_type
  grok {
    match  => { "message" => "(?<ip>[0-9.]+) (?<>) \[(?<time>.+)\] \"(?<method>[A-Z]+) (?<ur>.+) (?<ver>[^\"]+)\" (?<req>[0-9]+) (?<size>[0-9]+) \"(?<url>.*)\" \"(?<web>.*)\""}
  }
  }
}
output{
  stdout { codec => "rubydebug" }    //定义输出格式
  if [type] == "weblog" {  //匹配到类型后再执行下列命令
  elasticsearch {
    hosts => ["IP","IP",...]   //数据库地址
    index => "索引名"      //要存到哪个索引中
    flush_size => 2000	//超过2000字节写一次，性能优化
    idle_flush_time => 10  //10分钟写入一次
  }
  }
} 
/opt/logstash/bin/logstash -f 配置文件路径  //开启logstash
输出格式：事件戳  主机名  数据

web客户端配置
vim /etc/rsyslog.conf
增加:local0.info  @@目标主机IP:514    //发送local0.info的日志到哪里
systemctl restart rsyslog
模拟产生日志
logger -p local0.info(日志文件) -t weblog(主题) "内容"
安装filebeat
修改配置文件/etc/filebeat/filebeat.yml
- /var/log/日志路径
document_type: 自定义类型
logstash:	//打开注释
hosts: ["logstash主机IP:5044"]
systemctl start filebeat




插件
备注：若不会写配置文件可以找帮助，插件文档的位置：
https://www.elastic.co/guide/en/logstash/current/index.html
https://github.com/logstash-plugins
/opt/logstash/bin/logstash-plugin list   //查看已有插件列表
logstash-插件使用的区域()-具体使用方式  //插件命名格式
codec：用于所有区域，编码格式
input：只能用于本区域，读取数据
filter：只能用于本区域，处理数据
output：只能用于本区域，输出数据

shell的网络重定向，man bash
发送tcp数据：echo xxx > /dev/tcp/目标IP/端口
发送udp数据：echo xxx > /dev/tcp/目标IP/端口
调试shell脚本时在#!/bin/bash -x可以显示运行过程
-\S  //匹配非空白
-\s  //匹配空白
-\d  //匹配数字




YAML简介
 YAML是什么
    是一个可读性高，用来表达数据序列的格式
   YAML(YAML Ain't Markup Language)
   YAML参考了多种语言
 YAML基础语法
  YAML结构通过空格来展示
   数组使用"- "来表示
   键值对使用": "来表示
  YAML使用一个固定的缩进风格表示数据层及结构关系
   一般每个缩进级别由两个以上空格组成
   #表示注释
 注意：
   不要使用tab，缩进是初学者容易出错的地方之一
   同一层级缩进必须对齐
 YAML的键值表示方法
   采用冒号分隔
   ：后面必须有一个空格
   YAML键值对：
    "key":"values"
    "key":
      - "values"
      - "values"
     key:
          - 
          key:values
          key:values
          - 
          key:values
          key:values   
          - 
          key:values
          key:values   

#########################################################################

Day03

ansible简介
 ansible可以实现
   -自动化部署APP
   -自动化管理配置项
   -自动化持续交付
   -自动化(AWS)云服务管理
 ansible优点
   -只需要SSH和Python即可使用
   -无客户端
  -ansible功能强大，模块丰富
   -上手容易，门槛低
   -基于Python开发，做二次开发更容易
   -使用公司比较多，社区活跃
 ansible特性
   -模块化设计，调用特定的模块完成特定任务
   -基于Python语言实现
   -其模块支持JSON等标准输出格式，可以采用任何编程语言重写
   
安装ansible
源码安装：
  下载源码
  安装依赖包python-setuptools，python-devel
  编译python setup.py build
  安装python setup.py install
pip方式安装：pip install ansible
Yum安装：
 yum install ansible
 ansible --version   //查看安装信息
 
ad-hoc
主机管理
 ansible配置文件查找顺序(可以创建多个cfg文件)
   -首先检测ANSIBLE_CONFIG变量定义的配置文件,环境变量
   -其次检查当前目录下的./ansible.cfg文件
   -再次检查当前用户家目录下~/ansible.cfg文件
   -最后检查/etc/ansible/ansible.cfg文件
 /etc/ansible/ansible.cfg是ansible的默认配置文件路径
修改/etc/ansible/ansible.cfg配置文件
 14:inventory   = /etc/ansible/hosts    //指定ansible分组文件目录
 61:host_key_checking = False	//关闭主机key检测，连接时不用输入yes
/etc/ansible/hosts格式
 [web]     //[组名称]
 web[1:10] ansible_ssh_user=root ansible_ssh_pass="密码" ansible_ssh_port=端口 等信息   //不连续的分行写，组成员(主机名或IP地址等)
 ...
 [app:children]	//添加关键字children，表示下方为组的名称
 组名		
 ...
 [app:vars]		//关键字vars，表示为app组所有主机定义用户，密码，端口等信息
 ansible_ssh_pass=123456
 ...
 
 查看hosts主机
 ansible [组名,...] --list-hosts   //显示组中所有主机，用all表示所有组
配置后端托管主机后测试
 ansible 组名或主机名 -m ping [-k表示手工输入密码] //ansible会使用ssh尝试去连接托管主机

/etc/ansible/ansible.cfg配置文件inventory参数说明
 -ansible_ssh_host   //将要连接的远程主机名与你想要设定的主机别名不同，可以通过此变量设置
 -ansible_ssh_port  //指定ssh端口号
 -ansible_ssh_user  //默认ssh用户名
 -ansible_ssh_pass  //ssh密码(这种凡是不安全，建议使用--ask-pass或ssh密钥)
 -ansible_sudo_pass  //sudo密码(建议使用--ask-sudo-pass)
 -ansible_sudo_exe  //sudo命令路径(适用1.8及以上版本)
 -ansible_connection  //与主机的连接类型，如：local，ssh或paramiko
 -ansible_ssh_private_key_file  //ssh使用的私钥文件，适用于有多个密钥，而不项适用SSH代理的情况
 -ansible_shell_type  //目标系统的shell类型，默认情况下，命令的执行使用sh语法
 -ansible_python_interpreter  //目标主机的python路径，适用系统中有多个python或路径不时/usr/bin/python

ansible多人使用时自定义配置文件(静态主机)
1.创建ansible.cfg文件
2.在配置文件中添加
 [defaults]
 inventory = 分组文件路径
 host_key_checking = False
3.在分组文件中添加分组信息
4.在当前文件路径下执行anzible(执行顺序要牢记)

动态主机
指将inventory指定的文件/etc/ansible/hosts改为python等各种脚本，按Json格式返回给ansible
注意主机部分必须时列表格式，Hostdata行中的hosts部分可以省略，但使用时必是hosts

批量执行
ansible命令基础
 格式：ansible <host-pattern> [options]
 ansible hosts -m modules -a mod args   //ansible通用格式
 host-pattern  主机或定义的分组
 选项：
  -M  指定模块路径
  -m  使用模块，默认command模块(远程命令执行命令模块)，常用
  -a  or --args模块参数，必带
  -i  imventory文件路径，或可执行脚本
  -k  使用交互式登陆密码
  -e  定义变量
  -v  详细信息，-vvvv开启debug模式

批量部署公钥私钥
1.ansible主机生成公钥私钥
 ssh-keygen -N '' -f /root/.ssh/id_rsa -t rsa -b 1024
2.给所有主机部署公钥
 ansible all -m authorized_key -a "
user=root   //给root用户部署密钥
exclusive=true  //当用户有密钥时，追加进去
manage_dir=true  //当.ssh目录不存在时，自动授权创建
key='$(< /root/.ssh/id_rsa.pub)'  //将公钥导入变量key中
" -k
3.验证
 ansible all -m ping 

批量配置管理---模块
ansible-doc模块
  -模块的手册相当于shell的man，非常重要
 -ansible-doc -l    列出所有模块
 -ansible-doc modulename  查看帮助
ping模块
  -测试网络连通性，ping模块没有参数
  -注：测试ssh的连通性，与命令ping不一样，小心区分
  
command模块
  -默认模块，远程执行命令
  -用法：ansible host-pattern -m command -a '[args]'
  注意事项：
    -该模块通过-a跟上要执行的命令可以直接执行，若命令里有如下字符则执行不成功
    -'<','>','|','&'等
    -该模块不启动shell(bash)直接在ssh进程中执行，所有使用到shell(bash)的命令执行都会失败
shell|raw模块
 -shell模块用法基本和command一样，区别是shell模块是通过/bin/sh进行执行命令，可以执行任意命令
 -raw模块，用法和shell模块一样，可以执行任意命令，使用很多系统
  -区别是raw没有chdir(锁定当前目录)、creates、removes参数
  -执行以下命令查看结果
   ansible all -m command -a 'chdir=/tmp touch f1'  //在/tmp下创建f1
   ansible all -m shell -a 'chdir=/tmp touch f1'  //在/tmp下创建f1
   ansible all -m raw -a 'chdir=/tmp touch f1'  //指定目录无效
script模块
  -在本地写脚本，然后使用script模块批量执行
  -注意：该脚本包含但不限于shell脚本，只要指定Sha-bang解释器的脚本可运行
  ansible hosts -m script -a "脚本"
  
copy模块
  -复制文件到远程主机，文件名一模一样
 -src：本地文件路径，复制远程主机的文件到本地，绝对路径和相对路径都可，路径为目录时会递归复制。若路径以"/"结尾，值复制目录里的内容，负责复制包含目录在内的内容，类似rsync
 -dest：远程主机路径，必选项。远程主机的绝对路径，如果源文件是一个目录，那该路径必须是目录
 -backup：覆盖前先备份原文件，备份文件包含时间信息。有两个选项：yes|no
 -force：若目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，设为no，则值有当目标主机的目标位置不存在该文件是才复制。默认为yes
  -复制文件
   ansible all -m copy -a "src=/etc/resolv.conf dest=/etc/resolv.conf"
  -复制目录
   ansible all -m copy -a "src=/etc/ dest=/etc/"
   
lineinfile|replace模块
  -类似sed的一种行编辑替换模块
 -path目标文件
 -regexp正则表达式，匹配要修改的地方
 -line替换后的结果,匹配到替换一整行
  ansible all -m lineinfile -a 'path="/etc/selinux/config" regexp="^SELINUX=" line="SELINUX=disabled"'
 -replace替换指定字符，只修改匹配到的关键词
   ansible all -m lineinfile -a 'path="/etc/selinux/config" regexp="^(SELINUX=).*" replace="\1disabled"'  //\1复制前面()内的所有内容
   
yum模块(大批量安装使用，有报错信息)
  -使用yum包管理器来管理软件包
 -config_file：yum的配置文件
 -disable_gpg_check:关闭gpg_check
 -disablerepo:不启用某个源
 -enablerepo:启用某个源
 -name：要进行操作的软件包名称，多个用逗号分隔，也可以传递一个url或一个本地的rpm包的路径
 -state：状态(installed,removed,latest)
  ansible db -m yum -a 'name="mariadb-server" state="installed"'
service模块
 -name：服务名
 -enabled：是否开机启动 yes|no
 -state：动作(started,stopped,restarted)
 -sleep:执行restarted，会在stop和start之间沉睡几秒
  ansible web -m service -a 'name="httpd" state="started"'
setup模块
  -主要用户获取客户端主机的各种信息，常用参数filter
 -filter过滤所需信息
  ansible other -m setup -a "filter=条件"

















